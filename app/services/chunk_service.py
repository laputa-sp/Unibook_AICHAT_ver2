"""
Chunk Service - í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
PDF í˜ì´ì§€ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• 
"""
import logging
import re
from typing import List, Dict

logger = logging.getLogger(__name__)


class ChunkService:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ì„œë¹„ìŠ¤

    ëª©ì :
    - LLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì— ë§ê²Œ í…ìŠ¤íŠ¸ ë¶„í• 
    - ì„ë² ë”© ëª¨ë¸ì˜ ìµœëŒ€ ì…ë ¥ ê¸¸ì´ ì¤€ìˆ˜
    - ì˜ë¯¸ ë‹¨ìœ„ ìœ ì§€ (ë¬¸ì¥, ë‹¨ë½ ê²½ê³„ ê³ ë ¤)
    """

    def __init__(
        self,
        chunk_size: int = 500,
        chunk_overlap: int = 50,
        min_chunk_size: int = 100
    ):
        """
        ì´ˆê¸°í™”

        Args:
            chunk_size: ì²­í¬ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜ (ê¸°ë³¸: 500)
            chunk_overlap: ì²­í¬ ê°„ ì˜¤ë²„ë© ë¬¸ì ìˆ˜ (ê¸°ë³¸: 50)
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸° (ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ë²„ë¦¼)
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.min_chunk_size = min_chunk_size
        self.logger = logging.getLogger(__name__)

    def split_text(self, text: str, metadata: Dict = None) -> List[Dict]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 

        ì „ëµ:
        1. ë‹¨ë½ ìš°ì„  ë¶„í•  (\\n\\n ê¸°ì¤€)
        2. ë¬¸ì¥ ë‹¨ìœ„ ë¶„í•  (. ! ? ê¸°ì¤€)
        3. ì²­í¬ í¬ê¸° ì¡°ì ˆ (overlap ì ìš©)

        Args:
            text: ë¶„í• í•  í…ìŠ¤íŠ¸
            metadata: ì²­í¬ì— í¬í•¨í•  ë©”íƒ€ë°ì´í„° (ì˜ˆ: page_number, pdf_id)

        Returns:
            ì²­í¬ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            [
                {
                    "text": "ì²­í¬ í…ìŠ¤íŠ¸",
                    "metadata": {...}
                },
                ...
            ]
        """
        if not text or not text.strip():
            return []

        metadata = metadata or {}

        # 1. ë‹¨ë½ ë¶„í• 
        paragraphs = self._split_by_paragraphs(text)

        # 2. ì²­í¬ ìƒì„±
        chunks = []
        current_chunk = ""

        for para in paragraphs:
            # ë‹¨ë½ì´ ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
            if len(para) > self.chunk_size:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                    current_chunk = ""

                # ê¸´ ë‹¨ë½ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                sentences = self._split_by_sentences(para)
                for sent in sentences:
                    if len(current_chunk) + len(sent) > self.chunk_size:
                        if current_chunk.strip():
                            chunks.append(current_chunk.strip())
                        # Overlap ì²˜ë¦¬
                        current_chunk = self._get_overlap(current_chunk) + sent
                    else:
                        current_chunk += (" " if current_chunk else "") + sent

            else:
                # ë‹¨ë½ì´ ì ë‹¹í•œ ê¸¸ì´ë©´ ì¶”ê°€
                if len(current_chunk) + len(para) > self.chunk_size:
                    if current_chunk.strip():
                        chunks.append(current_chunk.strip())
                    # Overlap ì²˜ë¦¬
                    current_chunk = self._get_overlap(current_chunk) + para
                else:
                    current_chunk += ("\n\n" if current_chunk else "") + para

        # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        # 3. ë©”íƒ€ë°ì´í„° ì¶”ê°€ ë° í¬ë§·íŒ…
        result = []
        for i, chunk_text in enumerate(chunks):
            # ë„ˆë¬´ ì‘ì€ ì²­í¬ëŠ” ì œì™¸
            if len(chunk_text) < self.min_chunk_size:
                continue

            chunk_data = {
                "text": chunk_text,
                "chunk_index": i,
                "char_count": len(chunk_text),
                "metadata": metadata.copy()
            }
            result.append(chunk_data)

        return result

    def _split_by_paragraphs(self, text: str) -> List[str]:
        """
        ë‹¨ë½ìœ¼ë¡œ ë¶„í•  (\\n\\n ê¸°ì¤€)

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            ë‹¨ë½ ë¦¬ìŠ¤íŠ¸
        """
        # 2ê°œ ì´ìƒì˜ ê°œí–‰ì„ ë‹¨ë½ êµ¬ë¶„ìë¡œ ê°„ì£¼
        paragraphs = re.split(r'\n\s*\n', text)
        return [p.strip() for p in paragraphs if p.strip()]

    def _split_by_sentences(self, text: str) -> List[str]:
        """
        ë¬¸ì¥ìœ¼ë¡œ ë¶„í•  (. ! ? ê¸°ì¤€)

        í•œêµ­ì–´/ì˜ì–´ ë¬¸ì¥ ê²½ê³„ ì¸ì‹

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
        """
        # í•œêµ­ì–´/ì˜ì–´ ë¬¸ì¥ ì¢…ê²° ê¸°í˜¸
        # .!? ë’¤ì— ê³µë°±ì´ë‚˜ ê°œí–‰ì´ ì˜¤ëŠ” ê²½ìš°
        sentence_endings = re.compile(r'([.!?]+[\s\n]+)')

        # ë¬¸ì¥ ë¶„í• 
        parts = sentence_endings.split(text)

        sentences = []
        current = ""

        for part in parts:
            current += part
            if sentence_endings.match(part):
                sentences.append(current.strip())
                current = ""

        # ë‚¨ì€ í…ìŠ¤íŠ¸
        if current.strip():
            sentences.append(current.strip())

        return [s for s in sentences if s]

    def _get_overlap(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ëë¶€ë¶„ì—ì„œ ì˜¤ë²„ë© ë¶€ë¶„ ì¶”ì¶œ

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            ì˜¤ë²„ë©í•  í…ìŠ¤íŠ¸ (ë’¤ì—ì„œ chunk_overlap ê¸¸ì´ë§Œí¼)
        """
        if len(text) <= self.chunk_overlap:
            return text

        # ë’¤ì—ì„œ overlap ê¸¸ì´ë§Œí¼ ê°€ì ¸ì˜¤ë˜, ë‹¨ì–´ ê²½ê³„ ê³ ë ¤
        overlap_text = text[-self.chunk_overlap:]

        # ë‹¨ì–´ ì¤‘ê°„ì´ ì•„ë‹Œ ê³µë°±ì—ì„œ ì‹œì‘í•˜ë„ë¡ ì¡°ì •
        space_index = overlap_text.find(' ')
        if space_index > 0 and space_index < len(overlap_text) // 2:
            overlap_text = overlap_text[space_index + 1:]

        return overlap_text

    def split_page_content(
        self,
        pdf_id: str,
        page_number: int,
        content: str
    ) -> List[Dict]:
        """
        PDF í˜ì´ì§€ ë‚´ìš©ì„ ì²­í¬ë¡œ ë¶„í•  (í¸ì˜ ë©”ì„œë“œ)

        Args:
            pdf_id: PDF ID
            page_number: í˜ì´ì§€ ë²ˆí˜¸
            content: í˜ì´ì§€ ë‚´ìš©

        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸ (metadata í¬í•¨)
        """
        metadata = {
            "pdf_id": pdf_id,
            "page_number": page_number
        }

        return self.split_text(content, metadata)

    def split_pages_batch(
        self,
        pdf_id: str,
        pages: List[Dict]
    ) -> List[Dict]:
        """
        ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ í•œë²ˆì— ì²­í¬ë¡œ ë¶„í• 

        Args:
            pdf_id: PDF ID
            pages: í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ [{"page_number": int, "content": str}, ...]

        Returns:
            ëª¨ë“  ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        all_chunks = []

        for page in pages:
            page_number = page.get('page_number')
            content = page.get('content', '')

            if not content or not content.strip():
                continue

            chunks = self.split_page_content(pdf_id, page_number, content)
            all_chunks.extend(chunks)

        self.logger.info(
            f"ğŸ“„ PDF {pdf_id}: {len(pages)}í˜ì´ì§€ â†’ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±"
        )

        return all_chunks


# Singleton ì¸ìŠ¤í„´ìŠ¤
_chunk_service = None

def get_chunk_service(
    chunk_size: int = 500,
    chunk_overlap: int = 50
) -> ChunkService:
    """
    ì²­í¬ ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ë°˜í™˜

    Args:
        chunk_size: ì²­í¬ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜
        chunk_overlap: ì²­í¬ ê°„ ì˜¤ë²„ë©

    Returns:
        ChunkService ì¸ìŠ¤í„´ìŠ¤
    """
    global _chunk_service
    if _chunk_service is None:
        _chunk_service = ChunkService(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
    return _chunk_service
